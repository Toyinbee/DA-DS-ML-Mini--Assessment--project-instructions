# ğŸš€ Project Instructions for Next-Gen Builders


Welcome!  
This document contains your project tasks and guidelines.  
Each participant should complete the task for **their selected track** only:

- ğŸ“Š Data Analyst
- ğŸ“ˆ Data Scientist
- ğŸ¤– Machine Learning Engineer

You have **24 hours** to complete and submit your task.  
Push your work to GitHub and paste your **public repo link** in the submission form.

---

## ğŸ“Š Data Analyst Project â€“ Supermarket Sales Analysis

### ğŸ“ Dataset
ğŸ”— [Download Dataset (Google Drive)](https://drive.google.com/drive/folders/1ZO7eDc6A7fCPPsBTAfplcXdwQ3H-yHr4)

### ğŸ¯ Task Objectives
You are to analyze the supermarket sales dataset to uncover trends and key business insights.
1. **Data Cleaning**
   - Handle nulls and fix data types
   - Convert date/time columns
   - Create new columns (e.g., Total Sales = Unit Price Ã— Quantity)

2. **Data Visualization**
   Create at least 3 visuals (Excel / Power BI / Tableau):
   - Top cities / product lines
   - Payment method insights
   - Gender & customer type behavior
   - Sales trend over time
   - Gross Income vs Quantity

3. **Insights Summary**
   Briefly answer:
   - What drives the most sales?
   - Underperforming areas?
   - Gender/customer-type behavior differences?
   - Month with highest/lowest sales and why?

4. **Push to GitHub**
   Create folder: `supermarket-sales-analysis/`
   Include:
   - Visual dashboard file
   - 2â€“3 screenshots
   - `README.md` with summary of findings

---
## ğŸ“ˆ Data Scientist Project â€“ Loan Default Prediction

### ğŸ“¥ Dataset  
ğŸ”— [Download Dataset (Google Drive)](https://drive.google.com/file/d/1ZWlARDidjll5Wf2m8e-TQI8-gjcBKM1I/view?usp=drivesdk)

### ğŸ¯ Task Objectives
You are to build a predictive model that determines whether a customer is likely to default on their loan based on the dataset provided.
1. **Preprocessing & Cleaning**
   - Handle missing values  
   - Convert categorical features to numeric  
   - Remove/impute outliers  
   - Create meaningful derived features (optional)

2. **Exploratory Data Analysis (EDA)**
   Create at least 2â€“3 visualizations:
   - Income vs loan default  
   - Age group vs loan default  
   - Loan grade vs interest rate  
   â• Explain observed patterns in your notebook or README

3. **Model Building**
   - Use Logistic Regression, Decision Tree, or Random Forest  
   - Evaluate using:
     - Accuracy, Precision, Recall  
     - Confusion Matrix  
   - Use train/test split or cross-validation

4. **Results Explanation**
   Summarize:
   - Key predictive features  
   - Business insights from the model

5. **Push to GitHub**
   Create folder: `loan-default-prediction/`  
   Include:
   - `notebook.ipynb`  
   - `README.md`  
   - `requirements.txt` (optional)
---

## ğŸ¤– Machine Learning Engineer Project â€“ Image Classification

### ğŸ“ Dataset  
ğŸ”— [Intel Image Dataset (Kaggle)](https://www.kaggle.com/datasets/puneet6060/intel-image-classification)

Use the **Train** folder only.  
Pick **any 3 classes** (e.g., forest, mountain, street)
Do not use the "Test" or "Predict" folders provided.
ğŸ‘‰ Perform your own train/test split in your code.

### ğŸ¯ Task Objectives

1. **Preprocessing**
   - Resize images (e.g., 64Ã—64)
   - Normalize pixel values
   - Encode labels

2. **Model Building**
   - Train a CNN (or use transfer learning: VGG, MobileNet, etc.)
   - Evaluate performance (accuracy or confusion matrix)

3. **Streamlit Deployment**
   - Build an app that lets users upload an image
   - Show the predicted class

4. **Push to GitHub**
   Create folder: `intel-image-classification/`
   Include:
   - `notebook.ipynb`
   - `streamlit_app.py`
   - `predict.py`
   - `README.md` describing your classes and setup

---

## âœ… Submission Reminder

- Only submit the GitHub link for **your assigned track**
- Make sure your repo is **public**
- Include screenshots or dashboards if needed
- You may add a short video walkthrough (optional)

---

ğŸ‘©ğŸ½â€ğŸ’» Good luck! Show us your data skills.
For support, reach out to the Hacktron 2025 Team.
